{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wait Wait, Don't Analyze Me!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![NPR logo](https://media.npr.org/branding/programs/wait-wait-dont-tell-me/branding_main-c5920a167d6a5d445ce86fac30b90454223b6b57.png \"One nerd's attempt to learn everything there is to know about NPR's greatest quiz show.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "[Wait Wait, Don't Tell Me!](https://www.npr.org/programs/wait-wait-dont-tell-me/) is NPR's longest-running news quiz show. Contestents call in to answer questions about the week's news, and a rotating cast of three panelists make jokes and parody newsworthy (and not-so-newsworthy) current events. Listening to \"Wait wait\" has been a highlight of my week since I was a kid, and it remains one of NPR's most popular segments. So what better way to show my appreciation than to take it apart and see what makes it tick?\n",
    "\n",
    "For this project, I have pulled text transcripts of each episode of \"Wait, Wait\", storing them as a MySQL library. I have two goals:\n",
    "1. Understand and predict jokes in the program.\n",
    "2. Create a \"Wait wait\" transcript generator, so that I don't have to wait a whole week between episodes!\n",
    "\n",
    "In this section, I will create a transcript generator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* 0 Data Processing\n",
    "    * 0.1 [Loading data](#data-loading)\n",
    "    * 0.2 [Example transcript](#data-example)\n",
    "    * 0.3 [Encoding transcripts](#data-encoding)\n",
    "    * 0.4 [Building a training set](#data-train)\n",
    "* 1 Modeling\n",
    "    * 1.1 [Model Architecture](#model-initialize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 0: Initial data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Loading the data <a name=\"loading\"></a>\n",
    "Before I can analyze the data, I must first load it and process it. To accomplish this, I wrote a simple function to load in text files containing the transcripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries I'll be using\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import mysql.connector\n",
    "import re\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "import time\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# change the default font size in figures to be larger\n",
    "font = {'size'   : 15}\n",
    "plt.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the database of wait wait don't tell me transcripts\n",
    "cnx = mysql.connector.connect(database='wait_wait',\n",
    "                              user='root')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to pull some transcripts from the database\n",
    "def pull_transcript(n=5):\n",
    "    # instantiate a cursor to select data from the database\n",
    "    curs = cnx.cursor()\n",
    "    curs.execute(f'select * from transcripts limit {n}')\n",
    "    \n",
    "    # pull the data and convert to a pandas dataframe\n",
    "    df = pd.DataFrame(data = np.array(curs.fetchmany(n)),columns=curs.column_names)\n",
    "    df = df.set_index('id')\n",
    "    \n",
    "    # close the cursor\n",
    "    curs.close()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go ahead and pull all of the transcripts from the database - this dataset happens to be small enough that I can load it all at once.\n",
    "\n",
    "I also divide the transcripts randomly into testing, training, and validation sets. This will ensure that when I perform analyses, I don't build models that over-fit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_transcripts = 4131\n",
    "transcript_df = pull_transcript(n=num_transcripts)\n",
    "\n",
    "# split the tables into testing and training sets, so that we don't over-fit. \n",
    "np.random.seed(42) # Ensures that the split is the same each round\n",
    "transcript_df['train'] = np.random.rand(num_transcripts)>.2\n",
    "transcript_df['test'] = transcript_df['train']==False\n",
    "\n",
    "# Further separate the training dataset into a training and validation set\n",
    "transcript_df['val'] = (np.random.rand(num_transcripts)>.8) & (transcript_df['train'])\n",
    "\n",
    "# ensure that the training and validation sets don't overlap\n",
    "transcript_df['train'] = transcript_df['train'] & (transcript_df['val']==False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_id</th>\n",
       "      <th>aired_at</th>\n",
       "      <th>url</th>\n",
       "      <th>segment</th>\n",
       "      <th>transcript</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-05-04</td>\n",
       "      <td>https://www.npr.org/templates/transcript/trans...</td>\n",
       "      <td>who</td>\n",
       "      <td>\\n    \\n        \\n    \\n\\n    BILL KURTIS: Fro...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-05-04</td>\n",
       "      <td>https://www.npr.org/templates/transcript/trans...</td>\n",
       "      <td>panel</td>\n",
       "      <td>\\n    \\n        \\n    \\n\\n    PETER SAGAL, HOS...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-05-04</td>\n",
       "      <td>https://www.npr.org/templates/transcript/trans...</td>\n",
       "      <td>bluff</td>\n",
       "      <td>\\n    \\n        \\n    \\n\\n    BILL KURTIS: Fro...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-05-04</td>\n",
       "      <td>https://www.npr.org/templates/transcript/trans...</td>\n",
       "      <td>job</td>\n",
       "      <td>\\n    \\n        \\n    \\n\\n    PETER SAGAL, HOS...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-05-04</td>\n",
       "      <td>https://www.npr.org/templates/transcript/trans...</td>\n",
       "      <td>panel</td>\n",
       "      <td>\\n    \\n        \\n    \\n\\n    PETER SAGAL, HOS...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-05-04</td>\n",
       "      <td>https://www.npr.org/templates/transcript/trans...</td>\n",
       "      <td>limerick</td>\n",
       "      <td>\\n    \\n        \\n    \\n\\n    PETER SAGAL, HOS...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-05-04</td>\n",
       "      <td>https://www.npr.org/templates/transcript/trans...</td>\n",
       "      <td>lightning</td>\n",
       "      <td>\\n    \\n        \\n    \\n\\n    PETER SAGAL, HOS...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-05-04</td>\n",
       "      <td>https://www.npr.org/templates/transcript/trans...</td>\n",
       "      <td>predictions</td>\n",
       "      <td>\\n    \\n        \\n    \\n\\n    PETER SAGAL, HOS...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-04-27</td>\n",
       "      <td>https://www.npr.org/templates/transcript/trans...</td>\n",
       "      <td>who</td>\n",
       "      <td>\\n    \\n        \\n    \\n\\n    BILL KURTIS: Fro...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-04-27</td>\n",
       "      <td>https://www.npr.org/templates/transcript/trans...</td>\n",
       "      <td>panel</td>\n",
       "      <td>\\n    \\n        \\n    \\n\\n    PETER SAGAL, HOS...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   episode_id    aired_at                                                url  \\\n",
       "id                                                                             \n",
       "1           1  2019-05-04  https://www.npr.org/templates/transcript/trans...   \n",
       "2           1  2019-05-04  https://www.npr.org/templates/transcript/trans...   \n",
       "3           1  2019-05-04  https://www.npr.org/templates/transcript/trans...   \n",
       "4           1  2019-05-04  https://www.npr.org/templates/transcript/trans...   \n",
       "5           1  2019-05-04  https://www.npr.org/templates/transcript/trans...   \n",
       "6           1  2019-05-04  https://www.npr.org/templates/transcript/trans...   \n",
       "7           1  2019-05-04  https://www.npr.org/templates/transcript/trans...   \n",
       "8           1  2019-05-04  https://www.npr.org/templates/transcript/trans...   \n",
       "9           2  2019-04-27  https://www.npr.org/templates/transcript/trans...   \n",
       "10          2  2019-04-27  https://www.npr.org/templates/transcript/trans...   \n",
       "\n",
       "        segment                                         transcript  train  \\\n",
       "id                                                                          \n",
       "1           who  \\n    \\n        \\n    \\n\\n    BILL KURTIS: Fro...   True   \n",
       "2         panel  \\n    \\n        \\n    \\n\\n    PETER SAGAL, HOS...   True   \n",
       "3         bluff  \\n    \\n        \\n    \\n\\n    BILL KURTIS: Fro...   True   \n",
       "4           job  \\n    \\n        \\n    \\n\\n    PETER SAGAL, HOS...   True   \n",
       "5         panel  \\n    \\n        \\n    \\n\\n    PETER SAGAL, HOS...  False   \n",
       "6      limerick  \\n    \\n        \\n    \\n\\n    PETER SAGAL, HOS...  False   \n",
       "7     lightning  \\n    \\n        \\n    \\n\\n    PETER SAGAL, HOS...  False   \n",
       "8   predictions  \\n    \\n        \\n    \\n\\n    PETER SAGAL, HOS...   True   \n",
       "9           who  \\n    \\n        \\n    \\n\\n    BILL KURTIS: Fro...   True   \n",
       "10        panel  \\n    \\n        \\n    \\n\\n    PETER SAGAL, HOS...   True   \n",
       "\n",
       "     test    val  \n",
       "id                \n",
       "1   False  False  \n",
       "2   False  False  \n",
       "3   False  False  \n",
       "4   False  False  \n",
       "5    True  False  \n",
       "6    True  False  \n",
       "7    True  False  \n",
       "8   False  False  \n",
       "9   False  False  \n",
       "10  False  False  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For simplicity, I'll set all letters to lower-case\n",
    "transcript_df.loc[:,'transcript'] = transcript_df.loc[:,'transcript'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Example transcript<a name=\"data-example\"></a>\n",
    "\n",
    "To understand the data, it helps to first see what the raw data looks like. Let's print a little bit of the transcript from the first dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    \n",
      "        \n",
      "    \n",
      "\n",
      "    bill kurtis: from npr and wbez chicago, this is wait wait... don't tell me, the npr news quiz. hey, arthur miller - step into this cruci-bill (ph).\n",
      "    (laughter)\n",
      "    kurtis: i'm bill kurtis. and here's your host at the chase bank auditorium in downtown chicago, peter sagal.\n",
      "    peter sagal, host: \n",
      "    thank you, bill. thank you, everybody.\n",
      "    (cheering)\n",
      "    sagal: thank you so much. we have a very interesting show for you today. later on, we're going to be talking to m\n"
     ]
    }
   ],
   "source": [
    "print(transcript_df.loc[1,'transcript'][:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n    \\n        \\n    \\n\\n    bill kurtis: from npr and wbez chicago, this is wait wait... don't tell me, the npr news quiz. hey, arthur miller - step into this cruci-bill (ph).\\n    (laughter)\\n    kurtis: i'm bill kurtis. and here's your host at the chase bank auditorium in downtown chicago, peter sagal.\\n    peter sagal, host: \\n    thank you, bill. thank you, everybody.\\n    (cheering)\\n    sagal: thank you so much. we have a very interesting show for you today. later on, we're going to be talking to microsoft co-founder steve ballmer. he is, we believe, the richest guest we've ever had. but, of course, your true wealth is measured in your friends. and this just in - he has more friends, too.\\n    (laughter)\\n    sagal: but first, as many of you know, the npr podcast feeds got all screwed up last week. people who tried to download our show got, for example, how i built this instead, for which i apologize. and the people who wanted how i built this got us, for which i apologize even more.\\n    (l\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_df.loc[1,'transcript'][:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially, we can note a number of features. First, audience responses are noted with the '(LAUGHTER)' marker and '(APPLAUSE)' marker. This will prove very useful, as we have an automatic metric for \"funniness\" of the preceding text. \n",
    "\n",
    "Speakers' names are in all caps, followed by a colon. Speakers are also separated by a line break and a tab, which could potentially be used to segment the text into phrases by various people. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.3 Encoding the text <a name='data-encoding'></a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be building a letter-based generator for now, so I want a way to encode both letters and punctuation as integers (eventually, to be transferred into a one-hot encoding scheme for transferring to the model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset includes 77 unique tokens\n"
     ]
    }
   ],
   "source": [
    "all_tokens = set(transcript_df.loc[transcript_df.train,'transcript'].str.cat())\n",
    "print(f'The dataset includes {len(all_tokens)} unique tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dictionary converting letters/punctuation to integers\n",
    "conversion_dict = {}\n",
    "for i, token in enumerate(all_tokens):\n",
    "    conversion_dict[token] = i\n",
    "    \n",
    "# Make a second dictionary to go in the other direction\n",
    "reversion_dict = dict( (v,k) for k, v in conversion_dict.items() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple function to encode transcript\n",
    "def encode_transcript(transcript):\n",
    "    return [conversion_dict.get(n,len(all_tokens)) for n in transcript]\n",
    "def decode_transcript(transcript):\n",
    "    return [reversion_dict.get(n,len(all_tokens)) for n in transcript]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode each of the transcripts by converting letters and punctuation to integers\n",
    "transcript_df['encoded'] = transcript_df.loc[:,'transcript'].apply(encode_transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_id</th>\n",
       "      <th>aired_at</th>\n",
       "      <th>url</th>\n",
       "      <th>segment</th>\n",
       "      <th>transcript</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "      <th>val</th>\n",
       "      <th>encoded</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-05-04</td>\n",
       "      <td>https://www.npr.org/templates/transcript/trans...</td>\n",
       "      <td>who</td>\n",
       "      <td>\\n    \\n        \\n    \\n\\n    bill kurtis: fro...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[5, 26, 26, 26, 26, 5, 26, 26, 26, 26, 26, 26,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-05-04</td>\n",
       "      <td>https://www.npr.org/templates/transcript/trans...</td>\n",
       "      <td>panel</td>\n",
       "      <td>\\n    \\n        \\n    \\n\\n    peter sagal, hos...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[5, 26, 26, 26, 26, 5, 26, 26, 26, 26, 26, 26,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-05-04</td>\n",
       "      <td>https://www.npr.org/templates/transcript/trans...</td>\n",
       "      <td>bluff</td>\n",
       "      <td>\\n    \\n        \\n    \\n\\n    bill kurtis: fro...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[5, 26, 26, 26, 26, 5, 26, 26, 26, 26, 26, 26,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-05-04</td>\n",
       "      <td>https://www.npr.org/templates/transcript/trans...</td>\n",
       "      <td>job</td>\n",
       "      <td>\\n    \\n        \\n    \\n\\n    peter sagal, hos...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[5, 26, 26, 26, 26, 5, 26, 26, 26, 26, 26, 26,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-05-04</td>\n",
       "      <td>https://www.npr.org/templates/transcript/trans...</td>\n",
       "      <td>panel</td>\n",
       "      <td>\\n    \\n        \\n    \\n\\n    peter sagal, hos...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[5, 26, 26, 26, 26, 5, 26, 26, 26, 26, 26, 26,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   episode_id    aired_at                                                url  \\\n",
       "id                                                                             \n",
       "1           1  2019-05-04  https://www.npr.org/templates/transcript/trans...   \n",
       "2           1  2019-05-04  https://www.npr.org/templates/transcript/trans...   \n",
       "3           1  2019-05-04  https://www.npr.org/templates/transcript/trans...   \n",
       "4           1  2019-05-04  https://www.npr.org/templates/transcript/trans...   \n",
       "5           1  2019-05-04  https://www.npr.org/templates/transcript/trans...   \n",
       "\n",
       "   segment                                         transcript  train   test  \\\n",
       "id                                                                            \n",
       "1      who  \\n    \\n        \\n    \\n\\n    bill kurtis: fro...   True  False   \n",
       "2    panel  \\n    \\n        \\n    \\n\\n    peter sagal, hos...   True  False   \n",
       "3    bluff  \\n    \\n        \\n    \\n\\n    bill kurtis: fro...   True  False   \n",
       "4      job  \\n    \\n        \\n    \\n\\n    peter sagal, hos...   True  False   \n",
       "5    panel  \\n    \\n        \\n    \\n\\n    peter sagal, hos...  False   True   \n",
       "\n",
       "      val                                            encoded  \n",
       "id                                                            \n",
       "1   False  [5, 26, 26, 26, 26, 5, 26, 26, 26, 26, 26, 26,...  \n",
       "2   False  [5, 26, 26, 26, 26, 5, 26, 26, 26, 26, 26, 26,...  \n",
       "3   False  [5, 26, 26, 26, 26, 5, 26, 26, 26, 26, 26, 26,...  \n",
       "4   False  [5, 26, 26, 26, 26, 5, 26, 26, 26, 26, 26, 26,...  \n",
       "5   False  [5, 26, 26, 26, 26, 5, 26, 26, 26, 26, 26, 26,...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories='auto', drop=None,\n",
       "              dtype=<class 'numpy.float64'>, handle_unknown='error',\n",
       "              n_values=None, sparse=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a one-hot encoder to finally yield data in a one-hot version\n",
    "onehotencoder = OneHotEncoder(categories='auto',sparse=False)\n",
    "onehotencoder.fit(np.concatenate(transcript_df.encoded.values).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to apply the one hot scheme to the integer-encoded values\n",
    "def one_hot_transcript(transcript):\n",
    "    integer_transcript = np.array(encode_transcript(transcript)).reshape(-1,1)\n",
    "    return onehotencoder.transform(integer_transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the encoded transcript values to the one-hot encodings\n",
    "transcript_df['encoded'] = transcript_df.loc[:,'transcript'].apply(one_hot_transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.4 Building a training set <a name='data-train'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build up the training set, we will be taking all of our training transcripts and breaking them up into pieces of a set size. The \"x\" values will be the set of encoded integers, and the \"y\" value will be the integer that immediately follows. The goal of the model will be to predict the next letter (or punctuation mark), given the previous letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "n_times = 100\n",
    "n_components = len(all_tokens)+1\n",
    "step_size = 50\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_data(transcript):\n",
    "    # makes calculating size easier to pre-build the iterator\n",
    "    iterator = range(0,transcript.shape[0]-step_size-n_times,step_size) \n",
    "    \n",
    "    # calculate the size of data we will be generating\n",
    "    n_examples = len(iterator)\n",
    "\n",
    "    # initialize x and y values\n",
    "    x = np.zeros([n_examples,n_times,n_components])\n",
    "    y = np.zeros([n_examples,n_components])\n",
    "\n",
    "    # fill in the values for each split\n",
    "    for step,startpos in enumerate(iterator):\n",
    "        x[step] = transcript[startpos:startpos+n_times,:]\n",
    "        y[step] = transcript[startpos+n_times,:]\n",
    "    \n",
    "    # return x and y\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For each element of the training transcript set, generate training data\n",
    "def combine_model_data(transcript_df):\n",
    "    x = list()\n",
    "    y = list()\n",
    "    for i,transcript in enumerate(transcript_df.encoded):\n",
    "        x_,y_ = generate_model_data(transcript)\n",
    "        x.append(x_)\n",
    "        y.append(y_)\n",
    "\n",
    "        # report progress\n",
    "        if i%50==0:\n",
    "            print(i)\n",
    "    \n",
    "    # combine all sets into arrays\n",
    "    x = np.concatenate(x,axis=0)\n",
    "    y = np.concatenate(y,axis=0)\n",
    "        \n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# keeping things small for now, to ensure my code base works before going in with everything\n",
    "x_train,y_train = combine_model_data(transcript_df[:10])\n",
    "x_val,y_val = combine_model_data(transcript_df[10:15])\n",
    "x_test,y_test = combine_model_data(transcript_df[15:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Building and Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Specifying model architecture <a name='model-initialize'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_36_env",
   "language": "python",
   "name": "py_36_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
