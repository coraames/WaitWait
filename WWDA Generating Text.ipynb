{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wait Wait, Don't Analyze Me!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![NPR logo](https://media.npr.org/branding/programs/wait-wait-dont-tell-me/branding_main-c5920a167d6a5d445ce86fac30b90454223b6b57.png \"One nerd's attempt to learn everything there is to know about NPR's greatest quiz show.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "[Wait Wait, Don't Tell Me!](https://www.npr.org/programs/wait-wait-dont-tell-me/) is NPR's longest-running news quiz show. Contestents call in to answer questions about the week's news, and a rotating cast of three panelists make jokes and parody newsworthy (and not-so-newsworthy) current events. Listening to \"Wait wait\" has been a highlight of my week since I was a kid, and it remains one of NPR's most popular segments. So what better way to show my appreciation than to take it apart and see what makes it tick?\n",
    "\n",
    "For this project, I have pulled text transcripts of each episode of \"Wait, Wait\", storing them as a MySQL library. I have two goals:\n",
    "1. Understand and predict jokes in the program.\n",
    "2. Create a \"Wait wait\" transcript generator, so that I don't have to wait a whole week between episodes!\n",
    "\n",
    "In this section, I will create a transcript generator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* 0 Data Processing\n",
    "    * 0.1 [Loading data](#data-loading)\n",
    "    * 0.2 [Example transcript](#data-example)\n",
    "    * 0.3 [Encoding transcripts](#data-encoding)\n",
    "    * 0.4 [Building a training set](#data-train)\n",
    "* 1 Modeling\n",
    "    * 1.1 [Model Architecture](#model-initialize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 0: Initial data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Loading the data <a name=\"loading\"></a>\n",
    "Before I can analyze the data, I must first load it and process it. To accomplish this, I wrote a simple function to load in text files containing the transcripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries I'll be using\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import mysql.connector\n",
    "import re\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "import time\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# change the default font size in figures to be larger\n",
    "font = {'size'   : 15}\n",
    "plt.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the database of wait wait don't tell me transcripts\n",
    "cnx = mysql.connector.connect(database='wait_wait',\n",
    "                              user='root')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to pull some transcripts from the database\n",
    "def pull_transcript(n=5):\n",
    "    # instantiate a cursor to select data from the database\n",
    "    curs = cnx.cursor()\n",
    "    curs.execute(f'select * from transcripts limit {n}')\n",
    "    \n",
    "    # pull the data and convert to a pandas dataframe\n",
    "    df = pd.DataFrame(data = np.array(curs.fetchmany(n)),columns=curs.column_names)\n",
    "    df = df.set_index('id')\n",
    "    \n",
    "    # close the cursor\n",
    "    curs.close()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go ahead and pull all of the transcripts from the database - this dataset happens to be small enough that I can load it all at once.\n",
    "\n",
    "I also divide the transcripts randomly into testing, training, and validation sets. This will ensure that when I perform analyses, I don't build models that over-fit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_transcripts = 4131\n",
    "transcript_df = pull_transcript(n=num_transcripts)\n",
    "\n",
    "# split the tables into testing and training sets, so that we don't over-fit. \n",
    "np.random.seed(42) # Ensures that the split is the same each round\n",
    "transcript_df['train'] = np.random.rand(num_transcripts)>.2\n",
    "transcript_df['test'] = transcript_df['train']==False\n",
    "\n",
    "# Further separate the training dataset into a training and validation set\n",
    "transcript_df['val'] = (np.random.rand(num_transcripts)>.8) & (transcript_df['train'])\n",
    "\n",
    "# ensure that the training and validation sets don't overlap\n",
    "transcript_df['train'] = transcript_df['train'] & (transcript_df['val']==False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_id</th>\n",
       "      <th>aired_at</th>\n",
       "      <th>url</th>\n",
       "      <th>segment</th>\n",
       "      <th>transcript</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-05-04</td>\n",
       "      <td>https://www.npr.org/templates/transcript/trans...</td>\n",
       "      <td>who</td>\n",
       "      <td>\\n    \\n        \\n    \\n\\n    BILL KURTIS: Fro...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-05-04</td>\n",
       "      <td>https://www.npr.org/templates/transcript/trans...</td>\n",
       "      <td>panel</td>\n",
       "      <td>\\n    \\n        \\n    \\n\\n    PETER SAGAL, HOS...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-05-04</td>\n",
       "      <td>https://www.npr.org/templates/transcript/trans...</td>\n",
       "      <td>bluff</td>\n",
       "      <td>\\n    \\n        \\n    \\n\\n    BILL KURTIS: Fro...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-05-04</td>\n",
       "      <td>https://www.npr.org/templates/transcript/trans...</td>\n",
       "      <td>job</td>\n",
       "      <td>\\n    \\n        \\n    \\n\\n    PETER SAGAL, HOS...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-05-04</td>\n",
       "      <td>https://www.npr.org/templates/transcript/trans...</td>\n",
       "      <td>panel</td>\n",
       "      <td>\\n    \\n        \\n    \\n\\n    PETER SAGAL, HOS...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-05-04</td>\n",
       "      <td>https://www.npr.org/templates/transcript/trans...</td>\n",
       "      <td>limerick</td>\n",
       "      <td>\\n    \\n        \\n    \\n\\n    PETER SAGAL, HOS...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-05-04</td>\n",
       "      <td>https://www.npr.org/templates/transcript/trans...</td>\n",
       "      <td>lightning</td>\n",
       "      <td>\\n    \\n        \\n    \\n\\n    PETER SAGAL, HOS...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-05-04</td>\n",
       "      <td>https://www.npr.org/templates/transcript/trans...</td>\n",
       "      <td>predictions</td>\n",
       "      <td>\\n    \\n        \\n    \\n\\n    PETER SAGAL, HOS...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-04-27</td>\n",
       "      <td>https://www.npr.org/templates/transcript/trans...</td>\n",
       "      <td>who</td>\n",
       "      <td>\\n    \\n        \\n    \\n\\n    BILL KURTIS: Fro...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-04-27</td>\n",
       "      <td>https://www.npr.org/templates/transcript/trans...</td>\n",
       "      <td>panel</td>\n",
       "      <td>\\n    \\n        \\n    \\n\\n    PETER SAGAL, HOS...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   episode_id    aired_at                                                url  \\\n",
       "id                                                                             \n",
       "1           1  2019-05-04  https://www.npr.org/templates/transcript/trans...   \n",
       "2           1  2019-05-04  https://www.npr.org/templates/transcript/trans...   \n",
       "3           1  2019-05-04  https://www.npr.org/templates/transcript/trans...   \n",
       "4           1  2019-05-04  https://www.npr.org/templates/transcript/trans...   \n",
       "5           1  2019-05-04  https://www.npr.org/templates/transcript/trans...   \n",
       "6           1  2019-05-04  https://www.npr.org/templates/transcript/trans...   \n",
       "7           1  2019-05-04  https://www.npr.org/templates/transcript/trans...   \n",
       "8           1  2019-05-04  https://www.npr.org/templates/transcript/trans...   \n",
       "9           2  2019-04-27  https://www.npr.org/templates/transcript/trans...   \n",
       "10          2  2019-04-27  https://www.npr.org/templates/transcript/trans...   \n",
       "\n",
       "        segment                                         transcript  train  \\\n",
       "id                                                                          \n",
       "1           who  \\n    \\n        \\n    \\n\\n    BILL KURTIS: Fro...   True   \n",
       "2         panel  \\n    \\n        \\n    \\n\\n    PETER SAGAL, HOS...   True   \n",
       "3         bluff  \\n    \\n        \\n    \\n\\n    BILL KURTIS: Fro...   True   \n",
       "4           job  \\n    \\n        \\n    \\n\\n    PETER SAGAL, HOS...   True   \n",
       "5         panel  \\n    \\n        \\n    \\n\\n    PETER SAGAL, HOS...  False   \n",
       "6      limerick  \\n    \\n        \\n    \\n\\n    PETER SAGAL, HOS...  False   \n",
       "7     lightning  \\n    \\n        \\n    \\n\\n    PETER SAGAL, HOS...  False   \n",
       "8   predictions  \\n    \\n        \\n    \\n\\n    PETER SAGAL, HOS...   True   \n",
       "9           who  \\n    \\n        \\n    \\n\\n    BILL KURTIS: Fro...   True   \n",
       "10        panel  \\n    \\n        \\n    \\n\\n    PETER SAGAL, HOS...   True   \n",
       "\n",
       "     test    val  \n",
       "id                \n",
       "1   False  False  \n",
       "2   False  False  \n",
       "3   False  False  \n",
       "4   False  False  \n",
       "5    True  False  \n",
       "6    True  False  \n",
       "7    True  False  \n",
       "8   False  False  \n",
       "9   False  False  \n",
       "10  False  False  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For simplicity, I'll set all letters to lower-case\n",
    "transcript_df.loc[:,'transcript'] = transcript_df.loc[:,'transcript'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Example transcript<a name=\"data-example\"></a>\n",
    "\n",
    "To understand the data, it helps to first see what the raw data looks like. Let's print a little bit of the transcript from the first dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    \n",
      "        \n",
      "    \n",
      "\n",
      "    bill kurtis: from npr and wbez chicago, this is wait wait... don't tell me, the npr news quiz. hey, arthur miller - step into this cruci-bill (ph).\n",
      "    (laughter)\n",
      "    kurtis: i'm bill kurtis. and here's your host at the chase bank auditorium in downtown chicago, peter sagal.\n",
      "    peter sagal, host: \n",
      "    thank you, bill. thank you, everybody.\n",
      "    (cheering)\n",
      "    sagal: thank you so much. we have a very interesting show for you today. later on, we're going to be talking to m\n"
     ]
    }
   ],
   "source": [
    "print(transcript_df.loc[1,'transcript'][:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n    \\n        \\n    \\n\\n    bill kurtis: from npr and wbez chicago, this is wait wait... don't tell me, the npr news quiz. hey, arthur miller - step into this cruci-bill (ph).\\n    (laughter)\\n    kurtis: i'm bill kurtis. and here's your host at the chase bank auditorium in downtown chicago, peter sagal.\\n    peter sagal, host: \\n    thank you, bill. thank you, everybody.\\n    (cheering)\\n    sagal: thank you so much. we have a very interesting show for you today. later on, we're going to be talking to microsoft co-founder steve ballmer. he is, we believe, the richest guest we've ever had. but, of course, your true wealth is measured in your friends. and this just in - he has more friends, too.\\n    (laughter)\\n    sagal: but first, as many of you know, the npr podcast feeds got all screwed up last week. people who tried to download our show got, for example, how i built this instead, for which i apologize. and the people who wanted how i built this got us, for which i apologize even more.\\n    (l\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_df.loc[1,'transcript'][:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially, we can note a number of features. First, audience responses are noted with the '(LAUGHTER)' marker and '(APPLAUSE)' marker. This will prove very useful, as we have an automatic metric for \"funniness\" of the preceding text. \n",
    "\n",
    "Speakers' names are in all caps, followed by a colon. Speakers are also separated by a line break and a tab, which could potentially be used to segment the text into phrases by various people. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.3 Encoding the text <a name='data-encoding'></a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be building a letter-based generator for now, so I want a way to encode both letters and punctuation as integers (eventually, to be transferred into a one-hot encoding scheme for transferring to the model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset includes 77 unique tokens\n"
     ]
    }
   ],
   "source": [
    "all_tokens = set(transcript_df.loc[transcript_df.train,'transcript'].str.cat())\n",
    "print(f'The dataset includes {len(all_tokens)} unique tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dictionary converting letters/punctuation to integers\n",
    "conversion_dict = {}\n",
    "for i, token in enumerate(all_tokens):\n",
    "    conversion_dict[token] = i\n",
    "    \n",
    "# Make a second dictionary to go in the other direction\n",
    "reversion_dict = dict( (v,k) for k, v in conversion_dict.items() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple function to encode transcript\n",
    "def encode_transcript(transcript):\n",
    "    return [conversion_dict.get(n,len(all_tokens)) for n in transcript]\n",
    "def decode_transcript(transcript):\n",
    "    return [reversion_dict.get(n,len(all_tokens)) for n in transcript]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode each of the transcripts by converting letters and punctuation to integers\n",
    "transcript_df['encoded'] = transcript_df.loc[:,'transcript'].apply(encode_transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_id</th>\n",
       "      <th>aired_at</th>\n",
       "      <th>url</th>\n",
       "      <th>segment</th>\n",
       "      <th>transcript</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "      <th>val</th>\n",
       "      <th>encoded</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-05-04</td>\n",
       "      <td>https://www.npr.org/templates/transcript/trans...</td>\n",
       "      <td>who</td>\n",
       "      <td>\\n    \\n        \\n    \\n\\n    bill kurtis: fro...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[44, 1, 1, 1, 1, 44, 1, 1, 1, 1, 1, 1, 1, 1, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-05-04</td>\n",
       "      <td>https://www.npr.org/templates/transcript/trans...</td>\n",
       "      <td>panel</td>\n",
       "      <td>\\n    \\n        \\n    \\n\\n    peter sagal, hos...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[44, 1, 1, 1, 1, 44, 1, 1, 1, 1, 1, 1, 1, 1, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-05-04</td>\n",
       "      <td>https://www.npr.org/templates/transcript/trans...</td>\n",
       "      <td>bluff</td>\n",
       "      <td>\\n    \\n        \\n    \\n\\n    bill kurtis: fro...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[44, 1, 1, 1, 1, 44, 1, 1, 1, 1, 1, 1, 1, 1, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-05-04</td>\n",
       "      <td>https://www.npr.org/templates/transcript/trans...</td>\n",
       "      <td>job</td>\n",
       "      <td>\\n    \\n        \\n    \\n\\n    peter sagal, hos...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[44, 1, 1, 1, 1, 44, 1, 1, 1, 1, 1, 1, 1, 1, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-05-04</td>\n",
       "      <td>https://www.npr.org/templates/transcript/trans...</td>\n",
       "      <td>panel</td>\n",
       "      <td>\\n    \\n        \\n    \\n\\n    peter sagal, hos...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[44, 1, 1, 1, 1, 44, 1, 1, 1, 1, 1, 1, 1, 1, 4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   episode_id    aired_at                                                url  \\\n",
       "id                                                                             \n",
       "1           1  2019-05-04  https://www.npr.org/templates/transcript/trans...   \n",
       "2           1  2019-05-04  https://www.npr.org/templates/transcript/trans...   \n",
       "3           1  2019-05-04  https://www.npr.org/templates/transcript/trans...   \n",
       "4           1  2019-05-04  https://www.npr.org/templates/transcript/trans...   \n",
       "5           1  2019-05-04  https://www.npr.org/templates/transcript/trans...   \n",
       "\n",
       "   segment                                         transcript  train   test  \\\n",
       "id                                                                            \n",
       "1      who  \\n    \\n        \\n    \\n\\n    bill kurtis: fro...   True  False   \n",
       "2    panel  \\n    \\n        \\n    \\n\\n    peter sagal, hos...   True  False   \n",
       "3    bluff  \\n    \\n        \\n    \\n\\n    bill kurtis: fro...   True  False   \n",
       "4      job  \\n    \\n        \\n    \\n\\n    peter sagal, hos...   True  False   \n",
       "5    panel  \\n    \\n        \\n    \\n\\n    peter sagal, hos...  False   True   \n",
       "\n",
       "      val                                            encoded  \n",
       "id                                                            \n",
       "1   False  [44, 1, 1, 1, 1, 44, 1, 1, 1, 1, 1, 1, 1, 1, 4...  \n",
       "2   False  [44, 1, 1, 1, 1, 44, 1, 1, 1, 1, 1, 1, 1, 1, 4...  \n",
       "3   False  [44, 1, 1, 1, 1, 44, 1, 1, 1, 1, 1, 1, 1, 1, 4...  \n",
       "4   False  [44, 1, 1, 1, 1, 44, 1, 1, 1, 1, 1, 1, 1, 1, 4...  \n",
       "5   False  [44, 1, 1, 1, 1, 44, 1, 1, 1, 1, 1, 1, 1, 1, 4...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories='auto', drop=None,\n",
       "              dtype=<class 'numpy.float64'>, handle_unknown='error',\n",
       "              n_values=None, sparse=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a one-hot encoder to finally yield data in a one-hot version\n",
    "onehotencoder = OneHotEncoder(categories='auto',sparse=False)\n",
    "onehotencoder.fit(np.concatenate(transcript_df.encoded.values).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to apply the one hot scheme to the integer-encoded values\n",
    "def one_hot_transcript(transcript):\n",
    "    integer_transcript = np.array(encode_transcript(transcript)).reshape(-1,1)\n",
    "    return onehotencoder.transform(integer_transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the encoded transcript values to the one-hot encodings\n",
    "transcript_df['encoded'] = transcript_df.loc[:,'transcript'].apply(one_hot_transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.4 Building a training set <a name='data-train'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build up the training set, we will be taking all of our training transcripts and breaking them up into pieces of a set size. The \"x\" values will be the set of encoded integers, and the \"y\" value will be the integer that immediately follows. The goal of the model will be to predict the next letter (or punctuation mark), given the previous letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "n_times = 100\n",
    "n_components = len(all_tokens)+1\n",
    "step_size = 50\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_data(transcript):\n",
    "    # makes calculating size easier to pre-build the iterator\n",
    "    iterator = range(0,transcript.shape[0]-step_size-n_times,step_size) \n",
    "    \n",
    "    # calculate the size of data we will be generating\n",
    "    n_examples = len(iterator)\n",
    "\n",
    "    # initialize x and y values\n",
    "    x = np.zeros([n_examples,n_times,n_components])\n",
    "    y = np.zeros([n_examples,n_components])\n",
    "\n",
    "    # fill in the values for each split\n",
    "    for step,startpos in enumerate(iterator):\n",
    "        x[step] = transcript[startpos:startpos+n_times,:]\n",
    "        y[step] = transcript[startpos+n_times,:]\n",
    "    \n",
    "    # return x and y\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For each element of the training transcript set, generate training data\n",
    "def combine_model_data(transcript_df):\n",
    "    x = list()\n",
    "    y = list()\n",
    "    for i,transcript in enumerate(transcript_df.encoded):\n",
    "        x_,y_ = generate_model_data(transcript)\n",
    "        x.append(x_)\n",
    "        y.append(y_)\n",
    "\n",
    "        # report progress\n",
    "        if i%50==0:\n",
    "            print(i)\n",
    "    \n",
    "    # combine all sets into arrays\n",
    "    x = np.concatenate(x,axis=0)\n",
    "    y = np.concatenate(y,axis=0)\n",
    "        \n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "# keeping things small for now, to ensure my code base works before going in with everything\n",
    "# x_train,y_train = combine_model_data(transcript_df.loc[:500,:])\n",
    "x_val,y_val     = combine_model_data(transcript_df.loc[1000:1200,  :])\n",
    "# x_test,y_test   = combine_model_data(transcript_df.loc[120:140, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.5 Data Generator\n",
    "This is a different way of making the data. Doing the massive conversion of transcript to one-hot encoding is pretty memory-intensive. One way to improve that is to only process some of the data at a time, using a generator. This could also enable me to add some additional randomization into my process, so I'm going to play around with it. This code is closely based on the tutorial here: https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    # Generates data for Keras\n",
    "    def __init__(self, df, batch_size=32,n_times=n_times,n_components=n_components,shuffle=True):\n",
    "        # Initialization\n",
    "        self.batch_size = batch_size\n",
    "        self.df = df.encoded\n",
    "        self.indices = np.copy(self.df.index.values)\n",
    "        self.dim = (batch_size,n_times,n_components)\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        # Denotes the number of batches per epoch\n",
    "        return len(self.df.index.values)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(self.indices[index])\n",
    "\n",
    "        return X, y\n",
    "\n",
    "#     def on_epoch_end(self):\n",
    "#         #'Updates indexes after each epoch'\n",
    "#         self.indices = self.df.index.values\n",
    "#         if self.shuffle == True:\n",
    "#             np.random.shuffle(self.indices)\n",
    "\n",
    "    def __data_generation(self, transcript_num):\n",
    "        #'Generates data containing batch_size samples' \n",
    "        # Initialization\n",
    "        X = np.empty(self.dim)\n",
    "        y = np.empty((self.batch_size,self.dim[-1]), dtype=int)\n",
    "\n",
    "        # Pull batch_size random samples from the specified transcript\n",
    "        indices = np.random.randint(low=0,\n",
    "                                    high=self.df[transcript_num].shape[0]-101,\n",
    "                                    size=self.batch_size)\n",
    "        \n",
    "        # for each start position, pull a sequence of 100 chars for X, and the 101'st char for y\n",
    "        for i, startpos in enumerate(indices):\n",
    "            # Store sample\n",
    "            X[i,] = self.df[transcript_num][i:i+100,:]\n",
    "\n",
    "            # Store class\n",
    "            y[i] = self.df[transcript_num][i+100,:]\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = DataGenerator(transcript_df.loc[transcript_df.train,:],shuffle=True)\n",
    "val_gen = DataGenerator(transcript_df.loc[transcript_df.val,:],shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Building and Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Generate transcript function\n",
    "First, specify a function that, given a model and a sample of text, will generate the next text for the transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict_transcript(sample,chars_to_generate=50):\n",
    "    sample = sample.reshape(1,sample.shape[0],sample.shape[1])\n",
    "    \n",
    "    # initialize the phrase\n",
    "    predicted_phrase = np.concatenate((sample,np.zeros((1,chars_to_generate,n_components))),axis=1)\n",
    "\n",
    "    for char in range(n_times,n_times+chars_to_generate):\n",
    "        # calculate the probability distribution\n",
    "        probability = model.predict(sample).squeeze()\n",
    "\n",
    "        # guess the next character and add it to our prediction\n",
    "        guess = np.random.choice(a=n_components,p=probability)\n",
    "        predicted_phrase[0,char,guess] = 1\n",
    "\n",
    "        # feed the results into the next step of the model\n",
    "        sample = predicted_phrase[:,(char+1-n_times):char+1,:]\n",
    "\n",
    "    # Convert to text\n",
    "    predicted_phrase = ''.join(decode_transcript(np.argmax(predicted_phrase,axis=-1).squeeze()))\n",
    "    \n",
    "    # Print result\n",
    "    print(predicted_phrase)\n",
    "    \n",
    "    # output the phrase\n",
    "    return predicted_phrase\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Specifying model architecture <a name='model-initialize'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to use a recurrent neural network to generate my text. There are other systems I would also like to play with in the future (e.g. Markov models, transformer network), but this will make a good start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential models are pretty simple, I'll start there.\n",
    "from keras.models import Model\n",
    "from keras.layers import GRU,Dense,Bidirectional,Input,Add,Dropout\n",
    "from keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter setting\n",
    "n_units = 32 # size of RNN layers\n",
    "\n",
    "# helper function to add in a middle GRU layer and sum the outputs+inputs to that layer\n",
    "def Add_GRU_layer(inp,n_units):\n",
    "    mid = Bidirectional(GRU(n_units,activation='tanh',input_shape=(n_times,n_components),return_sequences=True))(inp)\n",
    "    mid = \n",
    "    final = Add()([inp,mid])\n",
    "    return final\n",
    "\n",
    "# Define the model\n",
    "x_in = Input(shape=(None,n_components))\n",
    "\n",
    "# GRU layers\n",
    "x = Bidirectional(GRU(n_units,activation='tanh',input_shape=(n_times,n_components),return_sequences=True))(x_in)\n",
    "\n",
    "# middle layers, with skip-gram combinations\n",
    "for mid_layer in range(3):\n",
    "    x = Add_GRU_layer(x,n_units)\n",
    "\n",
    "# final layer, no returning sequences\n",
    "x = Bidirectional(GRU(256,activation='tanh',input_shape=(n_times,n_components),return_sequences=False))(x)\n",
    "\n",
    "dense_out = Dense(128,activation='relu')(x)\n",
    "dense_out = Dropout(rate=.25)(dense_out)\n",
    "\n",
    "dense_out = Dense(n_components,activation='softmax')(dense_out)\n",
    "\n",
    "model = Model(inputs=[x_in],outputs=[dense_out])\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           (None, None, 78)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_45 (Bidirectional (None, None, 64)     21312       input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_46 (Bidirectional (None, None, 64)     18624       bidirectional_45[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, None, 64)     0           bidirectional_45[0][0]           \n",
      "                                                                 bidirectional_46[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_47 (Bidirectional (None, None, 64)     18624       add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, None, 64)     0           add_23[0][0]                     \n",
      "                                                                 bidirectional_47[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_48 (Bidirectional (None, None, 64)     18624       add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, None, 64)     0           add_24[0][0]                     \n",
      "                                                                 bidirectional_48[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_49 (Bidirectional (None, None, 64)     18624       add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, None, 64)     0           add_25[0][0]                     \n",
      "                                                                 bidirectional_49[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_50 (Bidirectional (None, None, 64)     18624       add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, None, 64)     0           add_26[0][0]                     \n",
      "                                                                 bidirectional_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_51 (Bidirectional (None, None, 64)     18624       add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, None, 64)     0           add_27[0][0]                     \n",
      "                                                                 bidirectional_51[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_52 (Bidirectional (None, None, 64)     18624       add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, None, 64)     0           add_28[0][0]                     \n",
      "                                                                 bidirectional_52[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_53 (Bidirectional (None, None, 64)     18624       add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, None, 64)     0           add_29[0][0]                     \n",
      "                                                                 bidirectional_53[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_54 (Bidirectional (None, None, 64)     18624       add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, None, 64)     0           add_30[0][0]                     \n",
      "                                                                 bidirectional_54[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_55 (Bidirectional (None, None, 64)     18624       add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, None, 64)     0           add_31[0][0]                     \n",
      "                                                                 bidirectional_55[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_56 (Bidirectional (None, 512)          493056      add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 128)          65664       bidirectional_56[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 128)          0           dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 78)           10062       dropout_15[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 776,334\n",
      "Trainable params: 776,334\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callback to generate an example transcript prediction each time\n",
    "class generator_callback(Callback):\n",
    "    \n",
    "    def on_epoch_end(self,epoch=0,logs={}):\n",
    "        Predict_transcript(x_val[100]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "200/200 [==============================] - 158s 792ms/step - loss: 1.4938 - val_loss: 1.0600\n",
      "Epoch 2/50\n",
      "200/200 [==============================] - 160s 802ms/step - loss: 1.0948 - val_loss: 1.6815\n",
      "Epoch 3/50\n",
      " 93/200 [============>.................] - ETA: 1:22 - loss: 1.0611"
     ]
    }
   ],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',patience=5)\n",
    "progress_reporter = generator_callback()\n",
    "history = model.fit_generator(train_gen,\n",
    "                              validation_data=val_gen,\n",
    "                              epochs=50,\n",
    "                              steps_per_epoch=200,\n",
    "                              validation_steps=20,\n",
    "                              callbacks=[early_stopping])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(model.fit_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_36_env",
   "language": "python",
   "name": "py_36_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
